{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOV8zF7ZLbNfxjOFKrJd3b9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["\n","\n","# ***Lightweight Hybrid CNN & ConvNeXt-Tiny IDS for IoT Networks***\n","\n","\n","## üìå**Description**\n","\n","This project presents a **lightweight hybrid intrusion detection system (IDS)** for securing IoT networks by combining **CNN** and **ConvNeXt-Tiny** architectures. The model efficiently detects malicious network traffic while maintaining low computational cost, making it suitable for real-time IoT and edge environments.\n","\n","\n","### üîë **Key Points**\n","\n","* Hybrid CNN + ConvNeXt-Tiny architecture\n","* Low-level and deep feature fusion\n","* Trained on CICIoT2023 dataset\n","* Cross-dataset validation on CICIDS2017, BoT-IoT, and UNSW-NB15\n","* High accuracy with low inference latency\n","* Lightweight and edge-deployable IDS\n","\n"],"metadata":{"id":"DrGZMd69u5uH"}},{"cell_type":"markdown","source":["## üîπ **Cell 1 ‚Äî Install and Import Required Libraries**\n","\n","### üìå Description\n","\n","This cell sets up the software environment required for implementing the intrusion detection system.\n","\n","### üîë Key Points\n","\n","* Installs deep learning libraries such as PyTorch and Torchvision\n","* Imports data handling tools like NumPy and Pandas\n","* Loads visualization libraries for result analysis\n","* Includes Scikit-learn utilities for preprocessing and evaluation\n","* Ensures a reproducible and research-ready environment"],"metadata":{"id":"vL_pjJXoygev"}},{"cell_type":"code","source":["\n","# Install required libraries\n","!pip install torch torchvision torchaudio\n","!pip install pandas numpy scikit-learn matplotlib seaborn tqdm\n","\n","# Imports\n","import os\n","import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n","\n","from tqdm import tqdm\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RinFvjiAgCpj","executionInfo":{"status":"ok","timestamp":1768395523228,"user_tz":-330,"elapsed":29878,"user":{"displayName":"goku saint","userId":"02083164915096593950"}},"outputId":"45a96dd2-04f1-4a69-bc4e-5899a2b902ee"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.2)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"]}]},{"cell_type":"markdown","source":["## üîπ **Cell 2 ‚Äî Load Datasets**\n","\n","### üìå Description\n","\n","This cell loads the primary and cross-dataset files required for training and evaluation.\n","\n","### üîë Key Points\n","\n","* Mounts Google Drive to handle large datasets\n","* Loads CICIoT2023 as the primary training dataset\n","* Defines file paths for CICIDS2017, BoT-IoT, and UNSW-NB15\n","* Enables seamless dataset switching for cross-dataset validation\n","* Supports scalable experimentation"],"metadata":{"id":"1xOW9tckybYl"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"VjKUuKqdf1FT","executionInfo":{"status":"error","timestamp":1768395644508,"user_tz":-330,"elapsed":121275,"user":{"displayName":"goku saint","userId":"02083164915096593950"}},"outputId":"5972a6b3-93f9-4648-badb-0ae5105a07dd"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"mount failed","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1164749974.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Load Datasets (CICIoT2023 + Paths for Others)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Dataset paths (modify based on your Drive structure)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["#Load Datasets (CICIoT2023 + Paths for Others)\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Dataset paths (modify based on your Drive structure)\n","CICIOT_PATH = \"/content/drive/MyDrive/Datasets/CICIoT2023/CICIoT2023.csv\"\n","BOTIOT_PATH = \"/content/drive/MyDrive/Datasets/BOT-IOT/UNSW_2018_IoT_Botnet_Final.csv\"\n","UNSW_PATH = \"/content/drive/MyDrive/Datasets/UNSW-NB15/UNSW_NB15_testing-set.csv\"\n","\n","# Load primary dataset\n","df = pd.read_csv(CICIOT_PATH)\n","print(\"CICIoT2023 Loaded Successfully\")\n","\n","\n","CHECKPOINT_DIR = \"/content/drive/MyDrive/IDS_Checkpoints\"\n","os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n","\n","CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, \"ids_checkpoint.pth\")\n","\n","print(\"Checkpoint path:\", CHECKPOINT_PATH)\n"]},{"cell_type":"markdown","source":["## üîπ **Cell 3 ‚Äî Dataset Exploration**\n","\n","### üìå Description\n","\n","This cell explores the structure and distribution of the CICIoT2023 dataset.\n","\n","### üîë Key Points\n","\n","* Displays dataset shape and feature count\n","* Lists all feature and label columns\n","* Examines attack class distribution\n","* Identifies potential class imbalance\n","* Helps understand traffic behavior before modeling"],"metadata":{"id":"0oVZfxrRyZek"}},{"cell_type":"code","source":["#Dataset Exploration\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","\n","print(\"Dataset Shape:\", df.shape)\n","print(\"\\nColumns:\\n\", df.columns)\n","\n","\n","label_column = 'label'\n","\n","# Get counts\n","class_counts = df[label_column].value_counts()\n","\n","plt.figure(figsize=(12,6))\n","sns.barplot(x=class_counts.index, y=class_counts.values)\n","\n","plt.title(\"Attack Class Distribution (CICIoT2023)\", fontsize=14)\n","plt.xlabel(\"Attack Class\")\n","plt.ylabel(\"Number of Samples\")\n","plt.xticks(rotation=45)\n","plt.grid(axis='y', linestyle='--', alpha=0.6)\n","\n","plt.show()\n","\n","\n","plt.figure(figsize=(12,6))\n","sns.barplot(x=class_counts.index, y=class_counts.values)\n","\n","plt.yscale(\"log\")   # log scale makes small classes visible\n","plt.title(\"Attack Class Distribution (Log Scale)\", fontsize=14)\n","plt.xlabel(\"Attack Class\")\n","plt.ylabel(\"Number of Samples (log scale)\")\n","plt.xticks(rotation=45)\n","plt.grid(axis='y', linestyle='--', alpha=0.6)\n","\n","plt.show()\n","\n"],"metadata":{"id":"IL_jU43thHQs","executionInfo":{"status":"aborted","timestamp":1768395644518,"user_tz":-330,"elapsed":61,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üîπ **Cell 4 ‚Äî Data Preprocessing**\n","\n","### üìå Description\n","\n","This cell prepares raw network traffic data for deep learning.\n","\n","### üîë Key Points\n","\n","* Handles missing and null values\n","* Normalizes feature values for stable training\n","* Encodes attack labels into numeric form\n","* Performs stratified train‚Äìtest split\n","* Ensures fair and unbiased evaluation\n"],"metadata":{"id":"lc97Lv3zyUeI"}},{"cell_type":"code","source":["#Data Preprocessing\n","# Handle missing values\n","df.fillna(0, inplace=True)\n","\n","X = df.drop(columns=[label_column])\n","y = df[label_column]\n","\n","# Encode labels\n","le = LabelEncoder()\n","y = le.fit_transform(y)\n","\n","# Normalize features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",")\n","\n","print(\"Train shape:\", X_train.shape)\n","print(\"Test shape:\", X_test.shape)\n"],"metadata":{"id":"AgINB8BViXki","executionInfo":{"status":"aborted","timestamp":1768395644523,"user_tz":-330,"elapsed":60,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üîπ **Cell 5 ‚Äî Tensor Preparation**\n","\n","### üìå Description\n","\n","This cell converts preprocessed data into tensors suitable for CNN-based models.\n","\n","### üîë Key Points\n","\n","* Converts NumPy arrays into PyTorch tensors\n","* Reshapes data into 3D format for 1D CNN input\n","* Creates efficient DataLoader objects\n","* Enables batch-wise training and inference\n","* Improves memory and computational efficiency"],"metadata":{"id":"5mDE6K1wxqHh"}},{"cell_type":"code","source":["#Tensor Preparation\n","\n","# Convert to tensors\n","X_train_t = torch.tensor(X_train, dtype=torch.float32)\n","X_test_t = torch.tensor(X_test, dtype=torch.float32)\n","y_train_t = torch.tensor(y_train, dtype=torch.long)\n","y_test_t = torch.tensor(y_test, dtype=torch.long)\n","\n","# Reshape for CNN (N, C, L)\n","X_train_t = X_train_t.unsqueeze(1)\n","X_test_t = X_test_t.unsqueeze(1)\n","\n","train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=128, shuffle=True)\n","test_loader = DataLoader(TensorDataset(X_test_t, y_test_t), batch_size=128)\n"],"metadata":{"id":"W5SlRZwwisJZ","executionInfo":{"status":"aborted","timestamp":1768395644534,"user_tz":-330,"elapsed":67,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üîπ **Cell 6 ‚Äî Build CNN Feature Extractor**\n","\n","### üìå Description\n","\n","This cell defines a lightweight CNN module for low-level feature extraction.\n","\n","### üîë Key Points\n","\n","* Extracts spatial and statistical traffic patterns\n","* Captures local intrusion signatures\n","* Uses minimal convolution layers to reduce complexity\n","* Ensures fast inference\n","* Suitable for IoT and edge devices"],"metadata":{"id":"zXye0IDzxqWf"}},{"cell_type":"code","source":["#Build Lightweight CNN Feature Extractor\n","\n","class CNNFeatureExtractor(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv1d(1, 32, kernel_size=3, padding=1),\n","            nn.BatchNorm1d(32),\n","            nn.ReLU(),\n","            nn.MaxPool1d(2),\n","\n","            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU(),\n","            nn.AdaptiveAvgPool1d(1)\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        return x.view(x.size(0), -1)\n"],"metadata":{"id":"tTDKeqLtizp-","executionInfo":{"status":"aborted","timestamp":1768395644538,"user_tz":-330,"elapsed":68,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üîπ **Cell 7 ‚Äî Build ConvNeXt-Tiny Backbone**\n","\n","### üìå Description\n","\n","This cell implements a ConvNeXt-Tiny inspired architecture for deep feature learning.\n","\n","### üîë Key Points\n","\n","* Applies modern CNN design principles\n","* Uses depthwise and large-kernel convolutions\n","* Captures high-level semantic traffic features\n","* Improves representational power\n","* Maintains a lightweight computational footprint\n"],"metadata":{"id":"lPB8OJJLxkc7"}},{"cell_type":"code","source":["#Build ConvNeXt-Tiny Backbone\n","\n","class ConvNeXtTiny1D(nn.Module):\n","    def __init__(self, in_channels=1):\n","        super().__init__()\n","        self.stem = nn.Conv1d(in_channels, 64, kernel_size=7, stride=2, padding=3)\n","        self.block = nn.Sequential(\n","            nn.BatchNorm1d(64),\n","            nn.ReLU(),\n","            nn.Conv1d(64, 128, kernel_size=7, padding=3, groups=64),\n","            nn.ReLU(),\n","            nn.AdaptiveAvgPool1d(1)\n","        )\n","\n","    def forward(self, x):\n","        x = self.stem(x)\n","        x = self.block(x)\n","        return x.view(x.size(0), -1)\n"],"metadata":{"id":"1vIG0X5ki47u","executionInfo":{"status":"aborted","timestamp":1768395644542,"user_tz":-330,"elapsed":15,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üîπ **Cell 8 ‚Äî Hybrid Model Construction**\n","\n","### üìå Description\n","\n","This cell constructs the hybrid IDS by combining CNN and ConvNeXt-Tiny features.\n","\n","### üîë Key Points\n","\n","* Fuses low-level and deep feature representations\n","* Improves detection accuracy and robustness\n","* Reduces overfitting through complementary learning\n","* Uses fully connected layers for classification\n","* Aligns with hybrid IDS research methodology"],"metadata":{"id":"poXhaDx-xiXn"}},{"cell_type":"code","source":["#Hybrid CNN + ConvNeXt-Tiny Model\n","\n","class HybridIDS(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        self.cnn = CNNFeatureExtractor()\n","        self.convnext = ConvNeXtTiny1D()\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(64 + 128, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(128, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        f1 = self.cnn(x)\n","        f2 = self.convnext(x)\n","        fused = torch.cat((f1, f2), dim=1)\n","        return self.classifier(fused)\n"],"metadata":{"id":"UVNxmarajBsU","executionInfo":{"status":"aborted","timestamp":1768395644546,"user_tz":-330,"elapsed":17,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üîπ **Cell 9 ‚Äî Model Compilation**\n","\n","### üìå Description\n","\n","This cell configures the model for training.\n","\n","### üîë Key Points\n","\n","* Initializes the hybrid IDS architecture\n","* Uses cross-entropy loss for multi-class detection\n","* Applies Adam optimizer for faster convergence\n","* Supports GPU acceleration when available\n","* Verifies model architecture and parameter count\n"],"metadata":{"id":"_pxLlnDMxZF0"}},{"cell_type":"code","source":["#Model Compilation\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = HybridIDS(num_classes=len(np.unique(y))).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","print(model)\n"],"metadata":{"id":"5Z1qcMqijGid","executionInfo":{"status":"aborted","timestamp":1768395644776,"user_tz":-330,"elapsed":246,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","## üîπ **Cell 10 ‚Äî Checkpoint Function**\n","\n","### üìå Description\n","\n","This cell saves and loads the trained Hybrid CNN & ConvNeXt-Tiny IDS model using a checkpoint. It preserves model weights and preprocessing objects to ensure reproducibility and enable reuse without retraining.\n","\n","### üîë Points\n","\n","* Saves model in `.pth` format\n","* Stores scaler and label encoder\n","* Enables model reuse and cross-dataset testing\n","* Supports deployment readiness\n"],"metadata":{"id":"itNQ6-ztxMrL"}},{"cell_type":"code","source":["#IMPLEMENTING CHECKPONT FUNCTION\n","\n","def save_checkpoint(epoch, model, optimizer, best_val_loss):\n","    torch.save({\n","        \"epoch\": epoch,\n","        \"model_state\": model.state_dict(),\n","        \"optimizer_state\": optimizer.state_dict(),\n","        \"best_val_loss\": best_val_loss\n","    }, CHECKPOINT_PATH)\n","\n","    print(f\"‚úÖ Checkpoint saved at epoch {epoch+1}\")\n"],"metadata":{"id":"deQUphy9mBgD","executionInfo":{"status":"aborted","timestamp":1768395644784,"user_tz":-330,"elapsed":234,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_checkpoint(model, optimizer):\n","    if os.path.exists(CHECKPOINT_PATH):\n","        checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n","\n","        model.load_state_dict(checkpoint[\"model_state\"])\n","        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n","\n","        start_epoch = checkpoint[\"epoch\"] + 1\n","        best_val_loss = checkpoint[\"best_val_loss\"]\n","\n","        print(f\"‚úÖ Resumed training from epoch {start_epoch}\")\n","        return start_epoch, best_val_loss\n","    else:\n","        print(\"‚ö†Ô∏è No checkpoint found. Starting fresh.\")\n","        return 0, float(\"inf\")\n"],"metadata":{"id":"pCLU3Q0M1XM0","executionInfo":{"status":"aborted","timestamp":1768395644792,"user_tz":-330,"elapsed":241,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# --------------------------------------\n","# Split TRAIN ‚Üí TRAIN + VALIDATION\n","# --------------------------------------\n","X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n","    X_train_t, y_train_t,\n","    test_size=0.15,        # 15% validation\n","    random_state=42,\n","    stratify=y_train_t\n",")\n","\n","# --------------------------------------\n","# Create DataLoaders\n","# --------------------------------------\n","train_loader = DataLoader(\n","    TensorDataset(X_train_split, y_train_split),\n","    batch_size=128,\n","    shuffle=True\n",")\n","\n","val_loader = DataLoader(\n","    TensorDataset(X_val_split, y_val_split),\n","    batch_size=128,\n","    shuffle=False\n",")\n","\n","print(\"‚úÖ train_loader and val_loader created\")\n","print(\"Train batches:\", len(train_loader))\n","print(\"Validation batches:\", len(val_loader))\n"],"metadata":{"id":"Yf8lycrO4Gmo","executionInfo":{"status":"aborted","timestamp":1768395644800,"user_tz":-330,"elapsed":18,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üîπ **Cell 11 ‚Äî Model Training**\n","\n","### üìå Description\n","\n","This cell trains the hybrid IDS model using labeled network traffic data.\n","\n","### üîë Key Points\n","\n","* Implements supervised training loop\n","* Updates model parameters across epochs\n","* Tracks training loss\n","* Visualizes convergence behavior\n","* Ensures stable and effective learning"],"metadata":{"id":"-x03BE9YwWql"}},{"cell_type":"code","source":["#COMPLETE TRAINING CELL\n","\n","# ======================================\n","# Training Configuration\n","# ======================================\n","epochs = 100\n","patience = 10\n","\n","train_losses = []\n","val_losses = []\n","val_accuracies = []\n","val_precisions = []\n","val_recalls = []\n","val_f1s = []\n","\n","# --------------------------------------\n","# Resume from checkpoint (if exists)\n","# --------------------------------------\n","start_epoch, best_val_loss = load_checkpoint(model, optimizer)\n","early_stop_counter = 0\n","\n","# ======================================\n","# Training Loop\n","# ======================================\n","for epoch in range(start_epoch, epochs):\n","\n","    # -------- TRAINING --------\n","    model.train()\n","    running_loss = 0.0\n","\n","    for Xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Training]\"):\n","        Xb, yb = Xb.to(device), yb.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(Xb)\n","        loss = criterion(outputs, yb)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    train_loss = running_loss / len(train_loader)\n","    train_losses.append(train_loss)\n","\n","    # -------- VALIDATION --------\n","    model.eval()\n","    val_running_loss = 0.0\n","    all_preds, all_labels = [], []\n","\n","    with torch.no_grad():\n","        for Xb, yb in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Validation]\"):\n","            Xb, yb = Xb.to(device), yb.to(device)\n","\n","            outputs = model(Xb)\n","            loss = criterion(outputs, yb)\n","            val_running_loss += loss.item()\n","\n","            preds = torch.argmax(outputs, dim=1)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(yb.cpu().numpy())\n","\n","    val_loss = val_running_loss / len(val_loader)\n","    val_losses.append(val_loss)\n","\n","    # -------- METRICS --------\n","    acc = accuracy_score(all_labels, all_preds)\n","    precision = precision_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n","    recall = recall_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n","    f1 = f1_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n","\n","    val_accuracies.append(acc)\n","    val_precisions.append(precision)\n","    val_recalls.append(recall)\n","    val_f1s.append(f1)\n","\n","    # -------- LOGGING --------\n","    print(\"\\n\" + \"=\"*60)\n","    print(f\"Epoch [{epoch+1}/{epochs}]\")\n","    print(f\"Train Loss : {train_loss:.4f}\")\n","    print(f\"Val Loss   : {val_loss:.4f}\")\n","    print(f\"Accuracy   : {acc:.4f}\")\n","    print(f\"Precision  : {precision:.4f}\")\n","    print(f\"Recall     : {recall:.4f}\")\n","    print(f\"F1 Score   : {f1:.4f}\")\n","    print(\"=\"*60)\n","\n","    # -------- CHECKPOINT + EARLY STOPPING --------\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        early_stop_counter = 0\n","        save_checkpoint(epoch, model, optimizer, best_val_loss)\n","    else:\n","        early_stop_counter += 1\n","        print(f\"Early stopping counter: {early_stop_counter}/{patience}\")\n","\n","        if early_stop_counter >= patience:\n","            print(\"üõë Early stopping triggered. Training stopped.\")\n","            break\n"],"metadata":{"id":"EUtm7y9rjYXx","executionInfo":{"status":"aborted","timestamp":1768395644803,"user_tz":-330,"elapsed":5,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üîπ **Cell 12 ‚Äî In-Dataset Evaluation**\n","\n","### üìå Description\n","\n","This cell evaluates model performance on the CICIoT2023 test dataset.\n","\n","### üîë Key Points\n","\n","* Computes accuracy, precision, recall, and F1-score\n","* Generates confusion matrix for detailed analysis\n","* Evaluates detection effectiveness per attack class\n","* Validates model performance on seen data\n","* Provides quantitative IDS metrics"],"metadata":{"id":"sNlJH7iuwGOr"}},{"cell_type":"code","source":["# ---------- Plot All Metrics ----------\n","plt.figure(figsize=(14,10))\n","\n","plt.subplot(2,2,1)\n","plt.plot(train_losses, label=\"Train Loss\")\n","plt.plot(val_losses, label=\"Val Loss\")\n","plt.title(\"Loss Curve\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.grid(True)\n","\n","plt.subplot(2,2,2)\n","plt.plot(val_accuracies, label=\"Accuracy\", color=\"green\")\n","plt.title(\"Validation Accuracy\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Accuracy\")\n","plt.grid(True)\n","\n","plt.subplot(2,2,3)\n","plt.plot(val_f1s, label=\"F1 Score\", color=\"purple\")\n","plt.title(\"Validation F1 Score\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"F1 Score\")\n","plt.grid(True)\n","\n","plt.subplot(2,2,4)\n","plt.plot(val_precisions, label=\"Precision\", color=\"orange\")\n","plt.plot(val_recalls, label=\"Recall\", color=\"red\")\n","plt.title(\"Precision & Recall\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Score\")\n","plt.legend()\n","plt.grid(True)\n","\n","plt.tight_layout()\n","\n","# ---------- SAVE FIGURE ----------\n","save_path = \"/content/drive/MyDrive/IDS_Results/\"\n","import os\n","os.makedirs(os.path.dirname(save_path), exist_ok=True)\n","\n","plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n","print(f\"‚úÖ Metrics plot saved at: {save_path}\")\n","\n","plt.show()\n"],"metadata":{"id":"EYVK-AHp30nG","executionInfo":{"status":"aborted","timestamp":1768395644808,"user_tz":-330,"elapsed":1,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üîπ **Cell 13 ‚Äî Lightweight Analysis**\n","\n","### üìå Description\n","\n","This cell evaluates the model‚Äôs suitability for IoT and edge deployment.\n","\n","### üîë Key Points\n","\n","* Calculates total and trainable model parameters\n","* Measures inference time and latency\n","* Assesses memory and computational efficiency\n","* Demonstrates real-time detection capability\n","* Justifies lightweight IDS design"],"metadata":{"id":"qicmT-d6v_aQ"}},{"cell_type":"code","source":["#Lightweight Analysis (IoT Feasibility Evaluation)\n","\n","# Model Size Calculation\n","# -------------------------------\n","total_params = sum(p.numel() for p in model.parameters())\n","trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f\"Total Parameters: {total_params:,}\")\n","print(f\"Trainable Parameters: {trainable_params:,}\")\n","print(f\"Model Size: {total_params / 1e6:.2f} Million Parameters\")\n","\n","# -------------------------------\n","# Inference Time Measurement\n","# -------------------------------\n","model.eval()\n","\n","# Warm-up (important for fair timing on GPU)\n","with torch.no_grad():\n","    _ = model(X_test_t[:100].to(device))\n","\n","start_time = time.time()\n","\n","with torch.no_grad():\n","    _ = model(X_test_t[:100].to(device))\n","\n","end_time = time.time()\n","\n","print(f\"Inference Time for 100 samples: {end_time - start_time:.4f} seconds\")\n","print(f\"Average inference time per sample: {(end_time - start_time)/100:.6f} seconds\")\n"],"metadata":{"id":"gk7_MKUApSFM","executionInfo":{"status":"aborted","timestamp":1768395644814,"user_tz":-330,"elapsed":151669,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üîπ **Cell 14 ‚Äî Baseline Comparison**\n","\n","### üìå Description\n","\n","This cell compares the proposed hybrid model with standard deep learning baselines.\n","\n","### üîë Key Points\n","\n","* Implements CNN-only baseline\n","* Evaluates CNN-GRU hybrid baseline\n","* Compares against Deep BiLSTM model\n","* Analyzes accuracy vs complexity trade-off\n","* Demonstrates superiority of the proposed hybrid IDS"],"metadata":{"id":"883h2T3VvyDU"}},{"cell_type":"code","source":["#Baseline Comparison\n","\n","#Baseline 1 ‚Äî CNN-only Model\n","\n","class CNNOnlyIDS(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv1d(1, 32, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool1d(2),\n","\n","            nn.Conv1d(32, 64, 3, padding=1),\n","            nn.ReLU(),\n","            nn.AdaptiveAvgPool1d(1)\n","        )\n","        self.classifier = nn.Linear(64, num_classes)\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        return self.classifier(x)\n","\n","#Baseline 2 ‚Äî CNN-GRU Model\n","\n","class CNNGRUIDS(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        self.cnn = nn.Sequential(\n","            nn.Conv1d(1, 32, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool1d(2)\n","        )\n","        self.gru = nn.GRU(input_size=32, hidden_size=64, batch_first=True)\n","        self.fc = nn.Linear(64, num_classes)\n","\n","    def forward(self, x):\n","        x = self.cnn(x)\n","        x = x.permute(0, 2, 1)  # (batch, seq, features)\n","        _, h = self.gru(x)\n","        return self.fc(h[-1])\n","\n","#Baseline 3 ‚Äî Deep BiLSTM Model\n","\n","class BiLSTMIDS(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        self.lstm = nn.LSTM(\n","            input_size=1,        # each feature as a time step\n","            hidden_size=64,\n","            num_layers=2,\n","            batch_first=True,\n","            bidirectional=True\n","        )\n","        self.fc = nn.Linear(128, num_classes)\n","\n","    def forward(self, x):\n","        # x shape: (batch, 1, features)\n","        x = x.permute(0, 2, 1)   # (batch, features, 1)\n","        _, (h, _) = self.lstm(x)\n","        h = torch.cat((h[-2], h[-1]), dim=1)\n","        return self.fc(h)\n","\n","\n"],"metadata":{"id":"A-N_0rxKpc0Z","executionInfo":{"status":"aborted","timestamp":1768395644820,"user_tz":-330,"elapsed":151674,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training & Evaluation Function (Reusable)\n","\n","def train_and_evaluate(model, train_loader, test_loader, epochs=5):\n","    model.to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    for _ in range(epochs):\n","        model.train()\n","        for Xb, yb in train_loader:\n","            Xb, yb = Xb.to(device), yb.to(device)\n","            optimizer.zero_grad()\n","            loss = criterion(model(Xb), yb)\n","            loss.backward()\n","            optimizer.step()\n","\n","    # Evaluation\n","    model.eval()\n","    y_true, y_pred = [], []\n","\n","    with torch.no_grad():\n","        for Xb, yb in test_loader:\n","            outputs = model(Xb.to(device))\n","            preds = outputs.argmax(dim=1).cpu().numpy()\n","            y_pred.extend(preds)\n","            y_true.extend(yb.numpy())\n","\n","    return {\n","        \"Accuracy\": accuracy_score(y_true, y_pred),\n","        \"Precision\": precision_score(y_true, y_pred, average='weighted'),\n","        \"Recall\": recall_score(y_true, y_pred, average='weighted'),\n","        \"F1\": f1_score(y_true, y_pred, average='weighted'),\n","        \"Params (M)\": sum(p.numel() for p in model.parameters()) / 1e6\n","    }\n"],"metadata":{"id":"dbX4EjHopiRn","executionInfo":{"status":"aborted","timestamp":1768395644826,"user_tz":-330,"elapsed":151680,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Baseline Experiments\n","results = []\n","\n","results.append((\"CNN-only\",\n","    train_and_evaluate(CNNOnlyIDS(len(np.unique(y))), train_loader, test_loader)))\n","\n","results.append((\"CNN-GRU\",\n","    train_and_evaluate(CNNGRUIDS(len(np.unique(y))), train_loader, test_loader)))\n","\n","results.append((\"BiLSTM\",\n","    train_and_evaluate(BiLSTMIDS(len(np.unique(y))), train_loader, test_loader)))\n","\n","results.append((\"Hybrid CNN + ConvNeXt-Tiny\",\n","    train_and_evaluate(model, train_loader, test_loader, epochs=0)))  # already trained\n"],"metadata":{"id":"_VvnmlvOqY6R","executionInfo":{"status":"aborted","timestamp":1768395644831,"user_tz":-330,"elapsed":151680,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert baseline results into DataFrame\n","baseline_df = pd.DataFrame([\n","    {\n","        \"Model\": name,\n","        \"Accuracy\": metrics[\"Accuracy\"],\n","        \"Precision\": metrics[\"Precision\"],\n","        \"Recall\": metrics[\"Recall\"],\n","        \"F1-Score\": metrics[\"F1\"],\n","        \"Parameters (M)\": metrics[\"Params (M)\"]\n","    }\n","    for name, metrics in results\n","])\n","\n","baseline_df\n","\n"],"metadata":{"id":"AHJfl4pp70ga","executionInfo":{"status":"aborted","timestamp":1768395644835,"user_tz":-330,"elapsed":151681,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Accuracy vs Model Complexity Plot\n","plt.figure(figsize=(8,6))\n","\n","plt.scatter(\n","    baseline_df[\"Parameters (M)\"],\n","    baseline_df[\"Accuracy\"],\n","    s=120\n",")\n","\n","for i, model_name in enumerate(baseline_df[\"Model\"]):\n","    plt.text(\n","        baseline_df[\"Parameters (M)\"][i],\n","        baseline_df[\"Accuracy\"][i],\n","        model_name,\n","        fontsize=9,\n","        ha=\"right\"\n","    )\n","\n","plt.xlabel(\"Model Parameters (Millions)\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Accuracy vs Model Complexity\")\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"XEYstzs386-5","executionInfo":{"status":"aborted","timestamp":1768395644838,"user_tz":-330,"elapsed":151679,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üîπ **Cell 15 ‚Äî Cross-Dataset Validation**\n","\n","### üìå Description\n","\n","This cell evaluates the trained model on unseen datasets without retraining.\n","\n","### üîë Key Points\n","\n","* Tests on BoT-IoT and UNSW-NB15 datasets\n","* Uses same scaler and label encoder\n","* Avoids retraining to ensure fair validation\n","* Measures generalization capability\n","* Demonstrates real-world applicability\n"],"metadata":{"id":"xDySrKOatjQ6"}},{"cell_type":"code","source":["#Cross-Dataset Validation\n","\n","def preprocess_cross_dataset(\n","    csv_path,\n","    reference_columns,\n","    scaler,\n","    label_column=\"Label\"\n","):\n","    df = pd.read_csv(csv_path)\n","\n","    # Drop label\n","    if label_column in df.columns:\n","        y = df[label_column]\n","        X = df.drop(columns=[label_column])\n","    else:\n","        raise ValueError(\"Label column not found!\")\n","\n","    # Keep only common features\n","    common_cols = list(set(reference_columns) & set(X.columns))\n","    X = X[common_cols]\n","\n","    # Reorder columns to match training\n","    X = X[reference_columns[:len(common_cols)]]\n","\n","    # Handle missing values\n","    X.fillna(0, inplace=True)\n","\n","    # Normalize using TRAIN scaler\n","    X_scaled = scaler.transform(X)\n","\n","    # Tensor reshape\n","    X_tensor = torch.tensor(X_scaled, dtype=torch.float32).unsqueeze(1)\n","\n","    return X_tensor, y\n"],"metadata":{"id":"-a7FHuzKq0sT","executionInfo":{"status":"aborted","timestamp":1768395644843,"user_tz":-330,"elapsed":151682,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load BoT-IoT\n","X_bot, y_bot = preprocess_cross_dataset(\n","    BOTIOT_PATH,\n","    reference_columns=X.columns,\n","    scaler=scaler\n",")\n","\n","# Encode labels using TRAIN encoder\n","y_bot = le.transform(y_bot)\n","\n","# Inference\n","model.eval()\n","bot_preds = []\n","\n","with torch.no_grad():\n","    for i in range(0, len(X_bot), 128):\n","        batch = X_bot[i:i+128].to(device)\n","        outputs = model(batch)\n","        preds = outputs.argmax(dim=1).cpu().numpy()\n","        bot_preds.extend(preds)\n","\n","# Metrics\n","print(\"BoT-IoT Cross-Dataset Results\")\n","print(\"Accuracy:\", accuracy_score(y_bot, bot_preds))\n","print(\"Precision:\", precision_score(y_bot, bot_preds, average='weighted'))\n","print(\"Recall:\", recall_score(y_bot, bot_preds, average='weighted'))\n","print(\"F1:\", f1_score(y_bot, bot_preds, average='weighted'))\n"],"metadata":{"id":"bAfYaHkorCsb","executionInfo":{"status":"aborted","timestamp":1768395644845,"user_tz":-330,"elapsed":151683,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load UNSW-NB15\n","X_unsw, y_unsw = preprocess_cross_dataset(\n","    UNSW_PATH,\n","    reference_columns=X.columns,\n","    scaler=scaler\n",")\n","\n","# Encode labels\n","y_unsw = le.transform(y_unsw)\n","\n","# Inference\n","unsw_preds = []\n","\n","with torch.no_grad():\n","    for i in range(0, len(X_unsw), 128):\n","        batch = X_unsw[i:i+128].to(device)\n","        outputs = model(batch)\n","        preds = outputs.argmax(dim=1).cpu().numpy()\n","        unsw_preds.extend(preds)\n","\n","# Metrics\n","print(\"UNSW-NB15 Cross-Dataset Results\")\n","print(\"Accuracy:\", accuracy_score(y_unsw, unsw_preds))\n","print(\"Precision:\", precision_score(y_unsw, unsw_preds, average='weighted'))\n","print(\"Recall:\", recall_score(y_unsw, unsw_preds, average='weighted'))\n","print(\"F1:\", f1_score(y_unsw, unsw_preds, average='weighted'))\n"],"metadata":{"id":"_0ULN9q-rEAh","executionInfo":{"status":"aborted","timestamp":1768395644849,"user_tz":-330,"elapsed":151686,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# FINAL CELL ‚Äî Save & Load Trained Model (.pth)\n","üìå Explanation (Markdown for Colab)\n","\n","After training and evaluation, the trained Hybrid CNN + ConvNeXt-Tiny IDS model is saved in PyTorch .pth format.\n","This allows:\n","\n","\n","*   Reproducibility of results\n","*   Cross-dataset testing without retraining\n","\n","*   Future deployment on IoT / edge devices\n","\n","\n","We save:\n","1. Model weights\n","2. Label encoder\n","3. Feature scaler\n","4. Model metadata\n"],"metadata":{"id":"-hfJoY9Ls3u2"}},{"cell_type":"code","source":["#Save & Load Trained Model\n","\n","# Create directory\n","save_dir = \"/content/drive/MyDrive/IDS_Models\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","# Model save path\n","model_path = os.path.join(save_dir, \"Hybrid_CNN_ConvNeXtTiny_IDS.pth\")\n","\n","# Save checkpoint\n","torch.save({\n","    \"model_state_dict\": model.state_dict(),\n","    \"num_classes\": len(np.unique(y)),\n","    \"scaler\": scaler,\n","    \"label_encoder\": le\n","}, model_path)\n","\n","print(f\"Model saved successfully at:\\n{model_path}\")\n","\n","\n","#Load Model(For Reuse / Cross-Dataset Testing)\n","\n","# Load checkpoint\n","checkpoint = torch.load(model_path, map_location=device)\n","\n","# Rebuild model\n","loaded_model = HybridIDS(num_classes=checkpoint[\"num_classes\"]).to(device)\n","loaded_model.load_state_dict(checkpoint[\"model_state_dict\"])\n","loaded_model.eval()\n","\n","# Load preprocessing objects\n","scaler = checkpoint[\"scaler\"]\n","le = checkpoint[\"label_encoder\"]\n","\n","print(\"Model loaded successfully and ready for inference.\")\n"],"metadata":{"id":"28TkZTYvsRTg","executionInfo":{"status":"aborted","timestamp":1768395644854,"user_tz":-330,"elapsed":151690,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"oDFbYwU4sSdT","executionInfo":{"status":"aborted","timestamp":1768395644860,"user_tz":-330,"elapsed":151695,"user":{"displayName":"goku saint","userId":"02083164915096593950"}}},"execution_count":null,"outputs":[]}]}